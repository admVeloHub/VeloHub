// OpenAI Service - Integra√ß√£o com IA para respostas inteligentes
const { OpenAI } = require('openai');
require('dotenv').config();

class OpenAIService {
  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
    this.model = "gpt-4o-mini"; // Modelo otimizado para custo
  }

  /**
   * Gera resposta inteligente baseada na pergunta e contexto
   * @param {string} question - Pergunta do usu√°rio
   * @param {string} context - Contexto da base de conhecimento
   * @param {Array} sessionHistory - Hist√≥rico da sess√£o
   * @param {string} userId - ID do usu√°rio
   * @returns {Promise<string>} Resposta gerada pela IA
   */
  async generateResponse(question, context = "", sessionHistory = [], userId = null) {
    try {
      // Construir prompt com contexto e hist√≥rico
      const prompt = this.buildPrompt(question, context, sessionHistory);
      
      console.log(`ü§ñ OpenAI: Processando pergunta para usu√°rio ${userId || 'an√¥nimo'}`);
      
      const completion = await this.openai.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "system",
            content: `Voc√™ √© o VeloBot, assistente oficial da Velotax. 
            Responda de forma clara, objetiva e √∫til em portugu√™s brasileiro.
            Use o contexto fornecido para dar respostas precisas.
            Se n√£o souber algo, seja honesto e sugira contatar o suporte.`
          },
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.2, // Baixa criatividade para respostas mais precisas
        max_tokens: 1024,
      });

      const response = completion.choices[0].message.content;
      
      console.log(`‚úÖ OpenAI: Resposta gerada com sucesso (${response.length} caracteres)`);
      
      return response;
      
    } catch (error) {
      console.error('‚ùå OpenAI Error:', error.message);
      
      // Fallback para resposta padr√£o
      return `Desculpe, n√£o consegui processar sua pergunta no momento. 
      Por favor, tente novamente ou entre em contato com nosso suporte.`;
    }
  }

  /**
   * Constr√≥i o prompt com contexto e hist√≥rico
   * @param {string} question - Pergunta atual
   * @param {string} context - Contexto da base de conhecimento
   * @param {Array} sessionHistory - Hist√≥rico da sess√£o
   * @returns {string} Prompt formatado
   */
  buildPrompt(question, context, sessionHistory) {
    let prompt = `### PERGUNTA ATUAL
"${question}"

### CONTEXTO DA BASE DE CONHECIMENTO
${context || "Nenhum contexto espec√≠fico encontrado."}

### HIST√ìRICO DA CONVERSA
${sessionHistory.length > 0 ? 
  sessionHistory.map(h => `${h.role}: ${h.content}`).join('\n') : 
  'Primeira pergunta da sess√£o.'}

### INSTRU√á√ïES
- Responda em portugu√™s brasileiro
- Seja direto e √∫til
- Use o contexto quando relevante
- Se n√£o souber, sugira contatar o suporte
- Mantenha tom profissional mas amig√°vel`;

    return prompt;
  }

  /**
   * Verifica se a API est√° configurada corretamente
   * @returns {boolean} Status da configura√ß√£o
   */
  isConfigured() {
    return !!process.env.OPENAI_API_KEY && process.env.OPENAI_API_KEY !== 'your_openai_api_key_here';
  }

  /**
   * Testa a conex√£o com a API OpenAI
   * @returns {Promise<boolean>} Status da conex√£o
   */
  async testConnection() {
    try {
      if (!this.isConfigured()) {
        console.warn('‚ö†Ô∏è OpenAI: API Key n√£o configurada');
        return false;
      }

      const completion = await this.openai.chat.completions.create({
        model: this.model,
        messages: [{ role: "user", content: "Teste de conex√£o" }],
        max_tokens: 10,
      });

      console.log('‚úÖ OpenAI: Conex√£o testada com sucesso');
      return true;
      
    } catch (error) {
      console.error('‚ùå OpenAI: Erro no teste de conex√£o:', error.message);
      return false;
    }
  }
}

module.exports = new OpenAIService();
